% function results = compareModels(X, Y)
% 
%     rng(1); % reproducible
% 
%     % Initialize results table
%     results = table("Model", 0.0, 'VariableNames', ["Model", "Accuracy"]);
%     results(1,:) = [];
% 
%     fprintf("\n===============================================\n");
%     fprintf("  MODEL KARŞILAŞTIRMA (5-FOLD CROSS VALIDATION)\n");
%     fprintf("===============================================\n\n");
% 
%     % ------------------ 1) Ensemble ------------------
%     M1 = fitcensemble(X, Y, 'Method', 'Bag', 'KFold', 5);
%     acc1 = 1 - kfoldLoss(M1);
%     results(end+1,:) = {"Ensemble (Bagging)", acc1};
% 
%     fprintf("1) Ensemble (Bagging)\n");
%     fprintf("   Accuracy = %.2f%%\n\n", acc1 * 100);
% 
%     % ------------------ 2) Decision Tree ------------------
%     M2 = fitctree(X, Y, 'KFold', 5);
%     acc2 = 1 - kfoldLoss(M2);
%     results(end+1,:) = {"Decision Tree", acc2};
% 
%     fprintf("2) Decision Tree\n");
%     fprintf("   Accuracy = %.2f%%\n\n", acc2 * 100);
% 
%     % ------------------ 3) SVM (ECOC / RBF) ------------------
%     t = templateSVM('KernelFunction', 'rbf');
%     M3 = fitcecoc(X, Y, 'Learners', t, 'KFold', 5);
%     acc3 = 1 - kfoldLoss(M3);
%     results(end+1,:) = {"SVM (ECOC RBF)", acc3};
% 
%     fprintf("3) SVM (ECOC / RBF Kernel)\n");
%     fprintf("   Accuracy = %.2f%%\n\n", acc3 * 100);
% 
%     % ------------------ 4) Naive Bayes ------------------
%     M4 = fitcnb(X, Y, 'KFold', 5);
%     acc4 = 1 - kfoldLoss(M4);
%     results(end+1,:) = {"Naive Bayes", acc4};
% 
%     fprintf("4) Naive Bayes\n");
%     fprintf("   Accuracy = %.2f%%\n\n", acc4 * 100);
% 
%     % ------------------ Accuracy Comparison Chart ------------------
%     figure;
%     bar(results.Accuracy * 100);
%     set(gca, 'XTickLabel', results.Model, 'XTick', 1:height(results));
%     xtickangle(45);
%     ylabel("Accuracy (%)");
%     title("Model Accuracy Comparison (5-Fold CV)");
% 
%     % ------------------ Best Model ------------------
%     [~, idx] = max(results.Accuracy);
% 
%     fprintf("===============================================\n");
%     fprintf("  BEST MODEL: %s (%.2f%%)\n", results.Model(idx), results.Accuracy(idx) * 100);
%     fprintf("===============================================\n\n");
% 
% end

function results = compareModels(X, Y)

results = struct();

fprintf("\n=========== MODEL COMPARISON (5-FOLD CV) ===========\n\n");

%% 1) SVM
t = templateSVM('KernelFunction','rbf');
M1 = fitcecoc(X, Y, 'Learners', t);
cvM1 = crossval(M1);

cvAcc1 = 1 - kfoldLoss(cvM1, 'LossFun', 'ClassifError');
results.SVM.model = M1;
results.SVM.cvModel = cvM1;
results.SVM.cvAcc = cvAcc1;

fprintf("SVM: %.2f%%\n", cvAcc1*100);


%% 2) Ensemble (Bagging)
M2 = fitcensemble(X, Y, 'Method','Bag');
cvM2 = crossval(M2);

cvAcc2 = 1 - kfoldLoss(cvM2, 'LossFun', 'ClassifError');
results.Ensemble.model = M2;
results.Ensemble.cvModel = cvM2;
results.Ensemble.cvAcc = cvAcc2;

fprintf("Ensemble: %.2f%%\n", cvAcc2*100);


%% 3) Naive Bayes
M3 = fitcnb(X, Y);
cvM3 = crossval(M3);

cvAcc3 = 1 - kfoldLoss(cvM3, 'LossFun', 'ClassifError');
results.NaiveBayes.model = M3;
results.NaiveBayes.cvModel = cvM3;
results.NaiveBayes.cvAcc = cvAcc3;

fprintf("Naive Bayes: %.2f%%\n", cvAcc3*100);


%% 4) Decision Tree
M4 = fitctree(X, Y);
cvM4 = crossval(M4);

cvAcc4 = 1 - kfoldLoss(cvM4, 'LossFun', 'ClassifError');
results.Tree.model = M4;
results.Tree.cvModel = cvM4;
results.Tree.cvAcc = cvAcc4;

fprintf("Decision Tree: %.2f%%\n", cvAcc4*100);


%% Best Model
[cvAccs, idx] = max([cvAcc1 cvAcc2 cvAcc3 cvAcc4]);
names = ["SVM","Ensemble","Naive Bayes","Decision Tree"];

fprintf("\nBEST MODEL → %s (%.2f%%)\n", names(idx), cvAccs*100);
fprintf("=====================================================\n\n");

end
